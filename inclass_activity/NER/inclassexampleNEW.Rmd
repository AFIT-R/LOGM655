---
title: "LOGM 655 - Examples"
subtitle: "Named Entity Recognition"
author: "MAJ Bryan Kolano, 2d Lt Nate Beveridge, 2d Lt Zachary Kane"
date: "`r format(Sys.Date(), '%d %b %Y')`"
output: 
  html_document:
    code_folding: 'hide'
---

# Named Entity Recognition using openNLP
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = F,
                      warning = F, 
                      comment = NA)

```

In order for openNLP to work, you must first download the following package
```{r open load, results='hide'}
 install.packages("openNLPmodels.en",
                 repos = "http://datacube.wu.ac.at/",
                 type = "source")
```
Next, load the following packages, or call them from the library.
```{r}

pacman::p_install(c("openNLP","coreNLP","readr","NLP","monkeylearn"))

# Or if you already have them installed, just load the libraries

library(openNLP)
library(NLP)
library(coreNLP)
library(monkeylearn)
```


Now that the packages are loaded, we need to insert the text documents

```{r}

rem <- readr::read_file("Remington.txt")
title <- c()
for (i in 1:4){
  j=1989
  title[i] <- paste("Bush_",j,".txt", sep = "")
  title <- c(title)
  j <- j + 1
}

title2 <- c()
for (i in 1:4){
  k=2001
    title2[i] <- paste("Bush_",k,".txt", sep = "")
  title2 <- c(title2)
  k <- k + 1
}


all <- c(title,title2)

for (i in seq_along(all))

```



# Named Entity Recognition using coreNLP


```{r}


```
# Named Entity Recognition using monkeylearn




# Challenges of Named Entity Recognition

The NER pieces of the different NLP packages worked fairly well for the State of the Union Addresses.  However, using the article from class on Monday, problems arose when attempting to identify persons, locations, and organizations.

```{r}
#first set the document as one string
s <- as.String(rem)

```

Next, we need to use the maximum entropy functions in openNLP to annotate the Remington document.

```{r}
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()

a2 <- annotate(text, list(sent_token_annotator, word_token_annotator))
```

Let's first look at the person entities
```{r}
## Entity recognition for persons.
entity_annotator <- Maxent_Entity_Annotator()
annotate(s, entity_annotator, a2)
## Directly:
entity_annotator(s, a2)
## And slice ...
s[entity_annotator(s, a2)]
```

Next, the location entities
```{r}
#Entity recognition for locations
entity_annotator_location <- Maxent_Entity_Annotator(kind = "location")
annotate(s, entity_annotator_location, a2)
## Directly:
entity_annotator_location(s, a2)
## And slice ...
s[entity_annotator_location(s, a2)]
## Variant with sentence probabilities as features.
annotate(s, Maxent_Entity_Annotator(probs = TRUE), a2)
```

Next, the organization entities
```{r}
#Entity Recognition for Organizations
entity_annotator_org <- Maxent_Entity_Annotator(kind = "organization")
annotate(s, entity_annotator_org, a2)
## Directly:
entity_annotator_org(s, a2)
## And slice ...
s[entity_annotator_org(s, a2)]
```

Finally, the date entities
```{r}
#Entity Recognition for dates
entity_annotator_date <- Maxent_Entity_Annotator(kind = "date")
annotate(s, entity_annotator_date, a2)
## Directly:
entity_annotator_date(s, a2)
## And slice ...
s[entity_annotator_date(s, a2)]
```



```



